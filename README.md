# Confluence_AI â€” AI Agent for Confluence Cloud

AIâ€‘Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ñ–Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ñ–Ñ— Ğ· Confluence Cloud, ÑĞºĞ¸Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·ÑƒÑ” Ñ‡Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ, Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·, ÑƒĞ·Ğ°Ğ³Ğ°Ğ»ÑŒĞ½ĞµĞ½Ğ½Ñ Ñ‚Ğ° Ğ¾Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½Ğ¾Ğº Ñƒ Ñ€Ğ¾Ğ±Ğ¾Ñ‡Ğ¾Ğ¼Ñƒ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ€Ñ– Ğ· Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ñ–Ğ·Ğ°Ñ†Ñ–Ñ”Ñ Ğ´Ğ»Ñ Ğ½Ğ°Ğ´Ñ–Ğ¹Ğ½Ğ¾Ñ— Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸ Ğ· AI API.

---

## ğŸ¯ ĞœĞµÑ‚Ğ° Ğ¿Ñ€Ğ¾Ñ”ĞºÑ‚Ñƒ

Ğ¡Ñ‚Ğ²Ğ¾Ñ€Ğ¸Ñ‚Ğ¸ Pythonâ€‘Ğ°Ğ³ĞµĞ½Ñ‚Ğ°, ÑĞºĞ¸Ğ¹:

- ğŸ“– Ñ‡Ğ¸Ñ‚Ğ°Ñ” ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºĞ¸ Confluence Ñ‡ĞµÑ€ĞµĞ· REST API  
- ğŸ§  Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·ÑƒÑ” ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ·Ğ° Ğ´Ğ¾Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ¾Ñ Ğ·Ğ¾Ğ²Ğ½Ñ–ÑˆĞ½Ñ–Ñ… AIâ€‘Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹  
- ğŸ“ Ğ³ĞµĞ½ĞµÑ€ÑƒÑ” summary, Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ—, ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ—  
- âœï¸ Ğ¾Ğ½Ğ¾Ğ²Ğ»ÑÑ” ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºĞ¸ Ğ°Ğ±Ğ¾ ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ” Ğ½Ğ¾Ğ²Ñ–  
- ğŸ” Ğ¿Ñ€Ğ°Ñ†ÑÑ” Ğ· Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼Ğ¸ Ñ‡ĞµÑ€ĞµĞ· `.env`  
- ğŸ—ï¸ Ğ¼Ğ°Ñ” Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒĞ½Ñƒ Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ°Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ Ñ€Ğ¾Ğ·ÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ

---

## âš¡ Optimization Patch v2.0 â€” What's New

### ğŸš€ **Performance Boost**
- **+14% Gemini success rate** (77.8% â†’ 92%+)
- **-90% 429 errors** (22% â†’ 2.2%)
- **-33% latency** (1300ms â†’ 867ms average)
- **15x better stability** (Â±4637ms â†’ Â±300ms)

### ğŸ”§ **Key Features**
1. **Pre-flight Rate Control** â€” Checks API readiness before requests, prevents 70% of rate limit errors
2. **Adaptive Cooldown** â€” Dynamic escalation (500ms â†’ 1500ms â†’ 7000ms) for consecutive errors
3. **Micro-batching** â€” Processes 46 pages in optimal batches (~2 items) with intelligent pausing
4. **Detailed Metrics** â€” Per-call statistics: success rate, fallback rate, response time, tokens
5. **Logging Rotation** â€” Automatic file rotation prevents disk exhaustion (10MB/file, 10 backups)

### ğŸ“Š **Control Run Results (46 pages)**
```
Operations:      46 pages (23 batches)
Success Rate:    92%+ (12/13 tracked)
429 Errors:      1 in 46 (2.2%)
Avg Response:    867ms âœ…
Max Response:    1566ms âœ…
Fallback Used:   1 (OpenAI seamless)
Status:          âœ… PRODUCTION READY
```

**ğŸ“š Full Documentation:** See [CHANGELOG.md](CHANGELOG.md) and [docs/PATCH_v2_INTEGRATION_COMPLETE_2026-01-04.md](docs/PATCH_v2_INTEGRATION_COMPLETE_2026-01-04.md)

---

## ğŸ§© Architecture

```
Confluence_AI/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/           # AI agents (tagging, summary, etc.)
â”‚   â”œâ”€â”€ api/              # FastAPI endpoints
â”‚   â”œâ”€â”€ clients/          # External API clients (Confluence, OpenAI, Gemini)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ ai/           # AI routing, optimization patch v2.0
â”‚   â”‚   â”œâ”€â”€ logging/      # Centralized logging with rotation
â”‚   â”‚   â”œâ”€â”€ whitelist/    # Page access control
â”‚   â”‚   â””â”€â”€ agent_mode_resolver/
â”‚   â”œâ”€â”€ services/         # Business logic (tagging, summary, context)
â”‚   â”œâ”€â”€ models/           # Data models (Pydantic)
â”‚   â””â”€â”€ utils/            # Helpers, HTML cleaning, etc.
â”‚
â”œâ”€â”€ tests/                # Unit and integration tests
â”œâ”€â”€ docs/                 # Documentation and architecture decisions
â”œâ”€â”€ logs/                 # Application logs (auto-rotated)
â”‚
â”œâ”€â”€ run_server.py         # FastAPI server entry point
â”œâ”€â”€ settings.py           # Environment configuration
â”œâ”€â”€ CHANGELOG.md          # Version history
â””â”€â”€ README.md             # This file
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

pip install -r requirements.txt
```

### 2. Configure Environment
```bash
cp .env.example .env
# Edit .env with your Confluence, OpenAI, and Gemini tokens
```

### 3. Run Server
```bash
python run_server.py
# API available at http://localhost:8000
```

### 4. Use API Endpoints
```bash
# Tag single page
curl -X POST http://localhost:8000/tagging/tag-page \
  -H "Content-Type: application/json" \
  -d '{"page_id": "123456", "mode": "DRY-RUN"}'

# Tag entire space
curl -X POST http://localhost:8000/tagging/tag-space/SPACE-KEY \
  -H "Content-Type: application/json" \
  -d '{"dry_run": true}'
```

---

## ğŸ“š Documentation

| Document | Purpose |
|----------|---------|
| [CHANGELOG.md](CHANGELOG.md) | Version history and features |
| [docs/architecture/](docs/architecture/) | System design and flows |
| [docs/PATCH_v2_INTEGRATION_COMPLETE_2026-01-04.md](docs/PATCH_v2_INTEGRATION_COMPLETE_2026-01-04.md) | v2.0 integration details |
| [docs/LOGGING_ROTATION_SETUP_2026-01-04.md](docs/LOGGING_ROTATION_SETUP_2026-01-04.md) | Log rotation configuration |
| [docs/adr/](docs/adr/) | Architecture Decision Records |

---

## ğŸ”Œ API Endpoints

### **Tagging**
- `POST /tagging/tag-page/{page_id}` â€” Tag single page
- `POST /tagging/tag-space/{space_key}` â€” Tag entire space
- `POST /tagging/tag-tree/{root_id}` â€” Tag page tree
- `POST /bulk/reset-tags/{space_key}` â€” Reset tags with tree scope

### **Utilities**
- `GET /health` â€” Health check
- `GET /metrics` â€” Performance metrics

See [docs/bulk-operations/](docs/bulk-operations/) for detailed endpoint documentation.

---

## ğŸ” Security

- ğŸ”’ Environment variables for all tokens (.env)
- ğŸ” Whitelist-based page access control
- ğŸ“ Audit logging for all operations
- ğŸ›¡ï¸ Security warnings for policy violations

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_tagging_service.py

# Run with coverage
pytest --cov=src

# Run integration tests
pytest tests/bulk/
```

---

## ğŸ“Š Monitoring

### **Logs**
- `logs/app.log` â€” Application logs
- `logs/ai_calls.log` â€” AI API calls (auto-rotated)
- `logs/audit.log` â€” Operation audit trail
- `logs/security.log` â€” Security events

### **Metrics**
- Success rate per AI provider
- Fallback rate and reasons
- Response time statistics
- Token usage tracking

---

## ğŸ› ï¸ Performance Optimization

### **v2.0 Optimization Patch**

The system now includes intelligent rate limit handling:

```python
# Automatic pre-flight checks
patch = get_optimization_patch_v2()
await patch.preflight_cooldown()  # Checks if API is ready

# Adaptive cooldown on rate limits
reason, wait_ms = await patch.adaptive_cooldown()
print(f"Waiting {wait_ms}ms due to: {reason}")

# Micro-batching for bulk operations
batches = patch.micro_batch(page_ids)
for batch in batches:
    # Process each batch with pause between
    process_batch(batch)
```

For implementation details, see [src/core/ai/optimization_patch_v2.py](src/core/ai/optimization_patch_v2.py)

---

## ğŸ“ˆ Roadmap

- [x] âœ… Core Confluence tagging with AI
- [x] âœ… Fallback to OpenAI when Gemini fails
- [x] âœ… Optimization Patch v2.0 (pre-flight, adaptive cooldown, micro-batching)
- [x] âœ… Centralized logging with rotation
- [ ] â³ Jira integration
- [ ] â³ Telegram notifications
- [ ] â³ CI/CD integration
- [ ] â³ Advanced caching layer

---

## ğŸ¤ Contributing

1. Create feature branch: `git checkout -b feature/your-feature`
2. Commit changes: `git commit -m "Add your feature"`
3. Push to branch: `git push origin feature/your-feature`
4. Open Pull Request

---

## ğŸ“ License

MIT License â€” See LICENSE file for details

---

## ğŸ“ Support

- **Issues:** [GitHub Issues](https://github.com/nkfed/Confluence_AI/issues)
- **Discussions:** [GitHub Discussions](https://github.com/nkfed/Confluence_AI/discussions)
- **Documentation:** See [docs/](docs/) folder

---

**Last Updated:** 2026-01-04  
**Version:** v2.0 (Optimization Patch)  
**Status:** âœ… Production Ready


