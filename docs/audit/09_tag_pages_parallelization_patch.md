# Patch: –ü–∞—Ä–∞–ª–µ–ª—ñ–∑–∞—Ü—ñ—è –æ–±—Ä–æ–±–∫–∏ tag-pages

**File:** `src/services/bulk_tagging_service.py`  
**Change:** –í–ø—Ä–æ–≤–∞–¥–∏—Ç–∏ asyncio.gather() –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏ —Å—Ç–æ—Ä—ñ–Ω–æ–∫  
**Expected Impact:** 100+ —Å–µ–∫ ‚Üí 30-50 —Å–µ–∫ –¥–ª—è 2-3 —Å—Ç–æ—Ä—ñ–Ω–æ–∫

---

## üìù –ö–æ–¥ –¥–ª—è –∑–∞–º—ñ–Ω–∏

### –ü–æ—Ç–æ—á–Ω–∏–π –∫–æ–¥ (–°–ï–†–Ü–ô–ù–ê –æ–±—Ä–æ–±–∫–∞)

**–õ–æ–∫–∞—Ü—ñ—è:** Lines 175-230 —É `tag_pages()` –º–µ—Ç–æ–¥—ñ

```python
        logger.info(
            f"[TagPages] Processing {len(filtered_ids)} allowed pages "
            f"(mode={mode}, effective_dry_run={effective_dry_run}, skipped={skipped_due_to_whitelist})"
        )

        # Process filtered pages only
        for page_id_int in filtered_ids:
            # ‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ –Ω–µ –∑—É–ø–∏–Ω–µ–Ω–æ –ø—Ä–æ—Ü–µ—Å
            if task_id and not ACTIVE_TASKS.get(task_id, True):
                logger.info(f"[TagPages] Task {task_id} stopped by user, breaking loop")
                break
            
            page_id = str(page_id_int)
            try:
                logger.info(f"[TagPages] Processing page {page_id} (effective_dry_run={effective_dry_run})")
                
                # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏
                page = await self.confluence.get_page(page_id)
                if not page:
                    logger.warning(f"[TagPages] Page {page_id} not found")
                    error_count += 1
                    results.append({
                        "page_id": page_id,
                        "status": "error",
                        "message": "Page not found"
                    })
                    continue
                
                text = page.get("body", {}).get("storage", {}).get("value", "")
                logger.debug(f"[TagPages] Extracted {len(text)} chars from page {page_id}")
                
                # –§–æ—Ä–º—É—î–º–æ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏–π AI-–ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–Ω—Ç—É
                logger.info(f"[TagPages] Calling TaggingAgent via router for page {page_id}")
                from src.agents.tagging_agent import TaggingAgent
                agent = TaggingAgent(ai_router=router)
                tags = await agent.suggest_tags(text)
                
                logger.info(f"[TagPages] Generated tags for {page_id}: {tags}")
                
                # ... rest of processing
                
            except Exception as e:
                logger.error(f"[TagPages] Failed to process page {page_id}: {e}")
                error_count += 1
                results.append({
                    "page_id": page_id,
                    "status": "error",
                    "message": str(e),
                    "tags": None
                })
            
            # ‚úÖ –û–Ω–æ–≤–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏ —Å—Ç–æ—Ä—ñ–Ω–∫–∏
            if task_id and task_id in TASK_PROGRESS:
                TASK_PROGRESS[task_id]["processed"] += 1

            # Throttling
            await asyncio.sleep(0.3)
```

---

### –ù–æ–≤–∏–π –∫–æ–¥ (–ü–ê–†–ê–õ–ï–õ–¨–ù–ê –æ–±—Ä–æ–±–∫–∞)

**–ó–∞–º—ñ–Ω–∞:**

```python
        logger.info(
            f"[TagPages] Processing {len(filtered_ids)} allowed pages "
            f"(mode={mode}, effective_dry_run={effective_dry_run}, skipped={skipped_due_to_whitelist})"
        )

        # ‚úÖ –í–Ω—É—Ç—Ä—ñ—à–Ω—è —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –æ–¥–Ω—ñ—î—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏
        async def process_single_page(page_id_int: int) -> dict:
            """
            –û–±—Ä–æ–±–ª—è—î –æ–¥–Ω—É —Å—Ç–æ—Ä—ñ–Ω–∫—É –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ.
            –ü–æ–≤–µ—Ä—Ç–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–æ–±–∫–∏ –∞–±–æ error dict.
            """
            page_id = str(page_id_int)
            
            # ‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ –Ω–µ –∑—É–ø–∏–Ω–µ–Ω–æ –ø—Ä–æ—Ü–µ—Å (–ø–µ—Ä–µ–¥ –æ–±—Ä–æ–±–∫–æ—é)
            if task_id and not ACTIVE_TASKS.get(task_id, True):
                logger.info(f"[TagPages] Task {task_id} stopped by user, skipping page {page_id}")
                return None  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ü—é —Å—Ç–æ—Ä—ñ–Ω–∫—É
            
            try:
                logger.info(f"[TagPages] Processing page {page_id} (effective_dry_run={effective_dry_run})")
                
                # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏
                page = await self.confluence.get_page(page_id)
                if not page:
                    logger.warning(f"[TagPages] Page {page_id} not found")
                    return {
                        "page_id": page_id,
                        "status": "error",
                        "message": "Page not found"
                    }
                
                text = page.get("body", {}).get("storage", {}).get("value", "")
                logger.debug(f"[TagPages] Extracted {len(text)} chars from page {page_id}")
                
                # –§–æ—Ä–º—É—î–º–æ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏–π AI-–ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–Ω—Ç—É
                logger.info(f"[TagPages] Calling TaggingAgent via router for page {page_id}")
                from src.agents.tagging_agent import TaggingAgent
                agent = TaggingAgent(ai_router=router)
                tags = await agent.suggest_tags(text)
                
                logger.info(f"[TagPages] Generated tags for {page_id}: {tags}")
                
                # Flatten tags and compare with existing
                flat_tags = flatten_tags(tags)
                logger.debug(f"[TagPages] Flattened tags: {flat_tags}")
                
                # Get existing labels
                existing_labels = await self.confluence.get_labels(page_id)
                logger.debug(f"[TagPages] Existing labels: {existing_labels}")
                
                # Calculate differences
                proposed = set(flat_tags)
                existing = set(existing_labels)
                to_add = proposed - existing
                
                logger.info(f"[TagPages] Tag comparison for {page_id}: proposed={len(proposed)}, existing={len(existing)}, to_add={len(to_add)}")
                
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ effective_dry_run –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ä–µ–∂–∏–º—É
                if effective_dry_run:
                    # –£ TEST —Ä–µ–∂–∏–º—ñ –≤—Å—ñ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–±–æ—Ä–æ–Ω–µ–Ω—ñ (–Ω–∞–≤—ñ—Ç—å –¥–ª—è whitelist —Å—Ç–æ—Ä—ñ–Ω–æ–∫)
                    status = "forbidden" if mode == "TEST" else "dry_run"
                    logger.info(f"[TagPages] [{status.upper()}] Would add labels for {page_id}: {list(to_add)}")
                    return {
                        "page_id": page_id,
                        "status": status,
                        "tags": {
                            "proposed": list(proposed),
                            "existing": list(existing),
                            "added": [],
                            "to_add": list(to_add)
                        },
                        "dry_run": True
                    }
                
                # Real update mode: page is already in whitelist (filtered_ids)
                if to_add:
                    logger.info(f"[TagPages] Updating labels for page {page_id}: adding {list(to_add)}")
                    await self.confluence.update_labels(page_id, list(to_add))
                    logger.info(f"[TagPages] Successfully updated labels for page {page_id}")
                else:
                    logger.info(f"[TagPages] No new labels to add for page {page_id}")
                
                return {
                    "page_id": page_id,
                    "status": "updated",
                    "tags": {
                        "proposed": list(proposed),
                        "existing": list(existing),
                        "added": list(to_add),
                        "to_add": []
                    },
                    "dry_run": False
                }

            except Exception as e:
                logger.error(f"[TagPages] Failed to process page {page_id}: {e}")
                return {
                    "page_id": page_id,
                    "status": "error",
                    "message": str(e),
                    "tags": None
                }
            finally:
                # ‚úÖ –û–Ω–æ–≤–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏ —Å—Ç–æ—Ä—ñ–Ω–∫–∏
                if task_id and task_id in TASK_PROGRESS:
                    TASK_PROGRESS[task_id]["processed"] += 1
                
                # Throttling - –¥–æ–±–∞–≤–ª—è—î–º–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω—É –∑–∞—Ç—Ä–∏–º–∫—É –¥–ª—è rate limiting
                await asyncio.sleep(0.1)  # –ó–º–µ–Ω—à–µ–Ω–æ –∑ 0.3 –∑ –æ–≥–ª—è–¥—É –Ω–∞ –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–º

        # ‚úÖ –ü–ê–†–ê–õ–ï–õ–¨–ù–ê –æ–±—Ä–æ–±–∫–∞: –∑–∞–ø—É—Å—Ç–∏—Ç–∏ –≤—Å—ñ –∑–∞–¥–∞—á—ñ –æ–¥–Ω–æ—á–∞—Å–Ω–æ
        logger.info(f"[TagPages] Starting parallel processing of {len(filtered_ids)} pages")
        
        if filtered_ids:
            tasks = [process_single_page(page_id_int) for page_id_int in filtered_ids]
            results_list = await asyncio.gather(*tasks, return_exceptions=False)
            
            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ None (—Å–∫–∞—Å–æ–≤–∞–Ω—ñ –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ –∑—É–ø–∏–Ω–∫—É) —Ç–∞ –æ–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            for result in results_list:
                if result is None:
                    continue  # –°—Ç–æ—Ä—ñ–Ω–∫–∞ —Å–∫–∞—Å–æ–≤–∞–Ω–∞
                
                results.append(result)
                
                if result.get("status") in ["updated", "dry_run"]:
                    success_count += 1
                elif result.get("status") == "error":
                    error_count += 1
        
        logger.info(f"[TagPages] Parallel processing completed: {success_count} success, {error_count} errors")
```

---

## üîÑ –†—ñ–∑–Ω–∏—Ü—è –ª–æ–≥—ñ–∫–∏

### –ü–ï–†–ï–î (—Å–µ—Ä—ñ–π–Ω–∞):
```
Page 111:  [====== AI 20s ======]
Page 222:                       [====== AI 20s ======]
Page 333:                                           [====== AI 20s ======]
Timeline:  0s         20s       40s       60s       80s      100s (SERIAL)
```

### –ü–Ü–°–õ–Ø (–ø–∞—Ä–∞–ª–µ–ª—å–Ω–∞):
```
Page 111:  [====== AI 20s ======]
Page 222:  [====== AI 20s ======] (–ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ!)
Page 333:  [====== AI 20s ======] (–ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ!)
Timeline:  0s         20s (PARALLEL)
```

---

## ‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è

### –¢–µ—Å—Ç –ø–µ—Ä–µ–¥ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è–º:
```bash
# –ó–∞–ø–∏—Ç –∑ 3 —Å—Ç–æ—Ä—ñ–Ω–∫–∞–º–∏
curl -X POST http://localhost:8000/bulk/tag-pages \
  -H "Content-Type: application/json" \
  -d '{
    "space_key": "nkfedba",
    "page_ids": ["111", "222", "333"],
    "dry_run": true
  }'

# –õ–æ–≥–∏:
# [TagPages] Processing 3 allowed pages
# [TagPages] Processing page 111 (effective_dry_run=True)
# [TagPages] Calling TaggingAgent via router for page 111
# [TagPages] Generated tags for 111: {...}
# [TagPages] Processing page 222 (effective_dry_run=True)
# ... (20-30 —Å–µ–∫ –Ω–∞ 111)
# [TagPages] Calling TaggingAgent via router for page 222
# ... (20-30 —Å–µ–∫ –Ω–∞ 222)
# [TagPages] Processing page 333
# ... (20-30 —Å–µ–∫ –Ω–∞ 333)
# TOTAL: ~60-90 —Å–µ–∫ (–°–ï–†–Ü–ô–ù–ê)
```

### –¢–µ—Å—Ç –ø—ñ—Å–ª—è –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:
```bash
# –¢–û–ô –ñ–ï –∑–∞–ø–∏—Ç
curl -X POST http://localhost:8000/bulk/tag-pages ...

# –õ–æ–≥–∏:
# [TagPages] Processing 3 allowed pages
# [TagPages] Starting parallel processing of 3 pages
# [TagPages] Processing page 111 (effective_dry_run=True)
# [TagPages] Processing page 222 (effective_dry_run=True)
# [TagPages] Processing page 333 (effective_dry_run=True)
# [TagPages] Calling TaggingAgent via router for page 111
# [TagPages] Calling TaggingAgent via router for page 222
# [TagPages] Calling TaggingAgent via router for page 333
# ... (20-30 —Å–µ–∫ - –í–°–Ü –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ!)
# [TagPages] Parallel processing completed
# TOTAL: ~20-40 —Å–µ–∫ (–ü–ê–†–ê–õ–ï–õ–¨–ù–ê) ‚Üê 2-3x —à–≤–∏–¥—á–µ!
```

---

## üìã Checklist –¥–ª—è –≤–ø—Ä–æ–≤–∞–¥–∂–µ–Ω–Ω—è

- [ ] –ë–µ–∫–∞–ø—ñ—Ç–∏ `src/services/bulk_tagging_service.py`
- [ ] –ó–∞–º—ñ–Ω–∏—Ç–∏ –ª–æ–≥—ñ–∫—É –æ–±—Ä–æ–±–∫–∏ –Ω–∞ asyncio.gather()
- [ ] –î–æ–±–∞–≤–∏—Ç–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è —á–∞—Å—É –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç–∏ unit —Ç–µ—Å—Ç–∏: `pytest tests/bulk/test_tag_pages.py`
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç–∏ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ–π–Ω–∏–π —Ç–µ—Å—Ç –∑ 3+ —Å—Ç–æ—Ä—ñ–Ω–∫–∞–º–∏
- [ ] –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ª–æ–≥–∏ –Ω–∞ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–µ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
- [ ] –í–∏–º—ñ—Ä–∏—Ç–∏ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è (–æ—á—ñ–∫—É–≤–∞–Ω–µ: 2-3x –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è)
- [ ] –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏, —â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–¥–Ω–∞–∫–æ–≤—ñ (processed, success, skipped)

---

**–ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å Fix:** üöÄ 2-3x –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è (100 —Å–µ–∫ ‚Üí 30-40 —Å–µ–∫)
