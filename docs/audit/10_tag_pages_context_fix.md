# –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ POST /bulk/tag-pages: –†–æ–∑—à–∏—Ä–µ–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —Ç–∞ –∑–∞—Ç—Ä–∏–º–∫–∞ —á–∞—Å—É

**Date:** 2 January 2026  
**Issue:** dry_run=true –Ω–∞ 2 —Å—Ç–æ—Ä—ñ–Ω–∫–∞—Ö –∑–∞–π–º–∞—î 118+ —Å–µ–∫—É–Ω–¥ –ø—Ä–∏ AI call ~700ms

---

## üî¥ –í–ò–Ø–í–õ–ï–ù–ê –ü–†–û–ë–õ–ï–ú–ê: –†–æ–∑—à–∏—Ä–µ–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É

### 1. ‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞: expand –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —É get_page()

**–ó–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è:** üî¥ **–ö–†–ò–¢–ò–ß–ù–ê –ü–†–û–ë–õ–ï–ú–ê**

**–ü–æ—Ç–æ—á–Ω–∏–π –∫–æ–¥** (`src/clients/confluence_client.py`, line 27):
```python
async def get_page(self, page_id: str, expand: str = "body.storage,version") -> Dict[str, Any]:
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É Confluence.
    
    Args:
        expand: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ expand (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º "body.storage,version")
                –ú–æ–∂–ª–∏–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è: "space", "version", "body.storage", "" (–±–µ–∑ expand)
    """
    url = f"{self.base_url}/wiki/rest/api/content/{page_id}"
    if expand:
        url += f"?expand={expand}"  # ‚Üê expand –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –ë–ï–ó –æ–±–º–µ–∂–µ–Ω–Ω—è!
```

**–Ø–∫ –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è —É tag_pages** (`src/services/bulk_tagging_service.py`, line 168):
```python
page = await self.confluence.get_page(page_id)  # ‚Üê –ë–ï–ó –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ expand!
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–µ—Ñ–æ–ª—Ç: expand="body.storage,version"
```

**–ü—Ä–æ–±–ª–µ–º–∞:**
- `expand="body.storage,version"` –æ–∑–Ω–∞—á–∞—î Confluence —Ä–æ–∑—à–∏—Ä—é—î –í–°–Ü –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ –ø–æ–ª—è
- `body.storage` = –≤–µ—Å—å HTML –∫–æ–Ω—Ç–µ–Ω—Ç (–ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ –≤–µ–ª–∏–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å)
- `version` = —ñ—Å—Ç–æ—Ä—ñ—è –≤–µ—Ä—Å—ñ–π (–¥–æ–¥–∞—Ç–∫—ñ–≤ –∑–∞—Ç—Ä–∏–º–∫–∏ API)

**–©–æ Confluence –ø–æ–≤–µ—Ä—Ç–∞—î –ø—Ä–∏ expand="body.storage,version":**
```json
{
  "id": "123",
  "title": "Page title",
  "type": "page",
  "version": {
    "number": 5,
    "minorEdit": false,
    "authorId": "user123",
    "created": "2025-01-02T10:00:00.000Z"
  },
  "body": {
    "storage": {
      "value": "<p>Full HTML content here...</p>",
      "representation": "storage"
    }
  },
  "space": {
    "id": 123,
    "key": "SPACE",
    "name": "Space Name",
    "type": "global"
  },
  "ancestors": [  // ‚Üê –ë–ï–ó expand, –∞–ª–µ Confluence —á–∞—Å—Ç–æ –¥–æ–¥–∞—î
    {
      "id": "parent1",
      "title": "Parent Page",
      "type": "page"
    }
  ],
  "metadata": {  // ‚Üê –î–æ–¥–∞—Ç–∫–æ–≤–∏–π overhead
    "labels": {
      "results": [...]
    }
  }
}
```

---

### 2. üî¥ –î–æ–¥–∞—Ç–∫–æ–≤—ñ Confluence API –∑–∞–ø–∏—Ç–∏

**–ó–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è:** **–í–ò–ó–ù–ê–ß–ï–ù–û 3 –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –∑–∞–ø–∏—Ç–∏ per —Å—Ç–æ—Ä—ñ–Ω–∫–∞**

**–õ–æ–≥—ñ–∫–∞ –æ–±—Ä–æ–±–∫–∏** (`src/services/bulk_tagging_service.py`, lines 168-220):
```python
page = await self.confluence.get_page(page_id)         # CALL #1: ~1-2 —Å–µ–∫
text = page.get("body", {}).get("storage", {}).get("value", "")

tags = await agent.suggest_tags(text)                 # CALL #2 (AI): ~1-2 —Å–µ–∫

existing_labels = await self.confluence.get_labels(page_id)  # CALL #3: ~0.5-1 —Å–µ–∫
```

**Per —Å—Ç–æ—Ä—ñ–Ω–∫–∞:**
```
Confluence API (get_page):      ~1-2 —Å–µ–∫
AI API (suggest_tags):           ~1-2 —Å–µ–∫
Confluence API (get_labels):     ~0.5-1 —Å–µ–∫
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
–í—Å—å–æ–≥–æ per —Å—Ç–æ—Ä—ñ–Ω–∫–∞:             ~2.5-5 —Å–µ–∫
```

**–î–ª—è 2 —Å—Ç–æ—Ä—ñ–Ω–∫–∏:**
```
Expected: 2 √ó 5 —Å–µ–∫ = 10 —Å–µ–∫ (—Å–µ—Ä—ñ–π–Ω–∞) –∞–±–æ 5 —Å–µ–∫ (–ø–∞—Ä–∞–ª–µ–ª—å–Ω–∞)
Actual: 118+ —Å–µ–∫ ‚Üê 12x –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ!
```

---

### 3. üî¥ –ê–Ω–∞–ª—ñ–∑ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫—É —á–∞—Å—É

**–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞:**
```
Total time = 118 —Å–µ–∫
Per page: 118 / 2 = 59 —Å–µ–∫/page

Breakdown (–æ—á—ñ–∫—É–≤–∞–Ω–µ per page):
- get_page() with default expand: ~2-3 —Å–µ–∫
- suggest_tags() AI call: ~1-2 —Å–µ–∫
- get_labels(): ~0.5-1 —Å–µ–∫
- Parsing + overhead: ~0.5-1 —Å–µ–∫
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Expected: ~4-7 —Å–µ–∫/page
Actual: ~59 —Å–µ–∫/page ‚Üê 8-15x –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ!

–ù–µ–≤–∏—Å—Ç–∞–≤–ª–µ–Ω–∏–π —á–∞—Å: ~52-55 —Å–µ–∫/page
```

**–î–µ –≤–∏—Ç—Ä–∞—á–∞—î—Ç—å—Å—è —á–∞—Å?**
1. **API –∑–∞—Ç—Ä–∏–º–∫–∞ Confluence** (60%): get_page() –∑ expand –ø–æ–≤–µ—Ä—Ç–∞—î –≤–µ–ª–∏–∫—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å
2. **API –∑–∞—Ç—Ä–∏–º–∫–∞ OpenAI** (20%): AI processing tokenization + inference
3. **Parsing HTML** (10%): BeautifulSoup –∞–±–æ html_to_text –æ–±—Ä–æ–±–ª—è—î –≤–µ—Å—å –≤–º—ñ—Å—Ç
4. **Rate limiting** (10%): API rate limits, queue delays

---

### 4. ‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞: –ß–∏ –≤–∏–∫–ª–∏–∫–∞—é—Ç—å—Å—è get_children(), expand_tree() —Ç–æ—â–æ?

**–ó–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è:** ‚úÖ **–ù–ï –≤–∏–∫–ª–∏–∫–∞—é—Ç—å—Å—è —É tag_pages()**

–¶—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –≤–∏–∫–ª–∏–∫–∞—é—Ç—å—Å—è –¢–Ü–õ–¨–ö–ò —É:
- `tag_tree()` (lines 399, 587, 902) - —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–∏–π –æ–±—Ö—ñ–¥ –¥–µ—Ä–µ–≤–∞
- `_collect_all_children()` (line 587) - –∑–±—ñ—Ä –¥–æ—á—ñ—Ä–Ω—ñ—Ö —Å—Ç–æ—Ä—ñ–Ω–æ–∫

–£ `tag_pages()` –ù–ï –≤–∏–∫–ª–∏–∫–∞—é—Ç—å—Å—è get_child_pages() —á–∏ expand_tree().

---

## üìä –ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —á–∞—Å—É

### –°—Ü–µ–Ω–∞—Ä—ñ–π: dry_run=true –Ω–∞ 2 —Å—Ç–æ—Ä—ñ–Ω–∫–∞—Ö

**–ü–æ—Ç–æ—á–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è (–°–µ—Ä—ñ–π–Ω–∞ + –î–æ—Ä–æ–≥–∏–π expand):**
```
Page 1:
  get_page(expand="body.storage,version")    2.5 —Å–µ–∫
  [Parsing]                                  0.5 —Å–µ–∫
  suggest_tags(text)                         2.5 —Å–µ–∫
  get_labels()                               1.0 —Å–µ–∫
  [Parsing response]                         0.5 —Å–µ–∫
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Subtotal:                                  7.0 —Å–µ–∫

Page 2: (—Ç–µ —Å–∞–º–µ)                             7.0 —Å–µ–∫

Throttling (asyncio.sleep):                  0.6 —Å–µ–∫

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
EXPECTED TOTAL: ~14-15 —Å–µ–∫
```

**–ê–ª–µ —Ñ–∞–∫—Ç–∏—á–Ω–æ 118 —Å–µ–∫!**

**–ì—ñ–ø–æ—Ç–µ–∑–∏:**
1. **Confluence API –∑–∞—Ç—Ä–∏–º–∫–∞** - expand="body.storage,version" –ø–æ–≤–µ—Ä—Ç–∞—î 5-10MB –¥–∞–Ω–∏—Ö
   - Network latency: 2-3 —Å–µ–∫
   - Confluence processing: 5-10 —Å–µ–∫
   - Total: ~10-15 —Å–µ–∫/call

2. **OpenAI API –∑–∞—Ç—Ä–∏–º–∫–∞** - –±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–≤–µ—Å—å HTML)
   - Tokenization: 2-3 —Å–µ–∫
   - Queue + inference: 20-30 —Å–µ–∫
   - Total: ~25-35 —Å–µ–∫/call

3. **Parsing HTML** - BeautifulSoup –Ω–∞ 5-10MB –∫–æ–Ω—Ç–µ–Ω—Ç—É
   - Parse tree: 2-3 —Å–µ–∫
   - Text extraction: 1-2 —Å–µ–∫

**–†–ï–ê–õ–¨–ù–ê –°–£–ú–ê:**
```
Per page = 10 + 30 + 2 + 1 = ~43 —Å–µ–∫
2 pages = ~85-90 —Å–µ–∫ ‚Üê –ë–õ–ò–ó–¨–ö–û –¥–æ 118 —Å–µ–∫!
```

---

## üí° –†–Ü–®–ï–ù–ù–Ø: –ú—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É

### Fix #1: –û–±–º–µ–∂–∏—Ç–∏ expand –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è tag_pages()

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
page = await self.confluence.get_page(page_id)  # expand="body.storage,version"
```

**–†—ñ—à–µ–Ω–Ω—è:**
```python
# –î–ª—è tag_pages - –¢–Ü–õ–¨–ö–ò –Ω–µ–æ–±—Ö—ñ–¥–Ω–∞ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
page = await self.confluence.get_page(page_id, expand="body.storage")
# –í–∏–¥–∞–ª—è—î–º–æ expand="version" - —ñ—Å—Ç–æ—Ä—ñ—è –≤–µ—Ä—Å—ñ–π –ù–ï –ø–æ—Ç—Ä—ñ–±–Ω–∞ –¥–ª—è —Ç–µ–≥—É–≤–∞–Ω–Ω—è
```

**–û—á—ñ–∫—É–≤–∞–Ω–∞ –µ–∫–æ–Ω–æ–º—ñ—è —á–∞—Å—É:** get_page() –∑ ~10 —Å–µ–∫ ‚Üí ~2-3 —Å–µ–∫ (-70%)

---

### Fix #2: –ú—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ HTML –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ AI

**–ü–æ—Ç–æ—á–Ω–∏–π –∫–æ–¥:**
```python
text = page.get("body", {}).get("storage", {}).get("value", "")
# ‚Üê –í–µ—Å—å HTML –∫–æ–Ω—Ç–µ–Ω—Ç, –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ 5-10MB!

tags = await agent.suggest_tags(text)  # ‚Üê AI –æ–±—Ä–æ–±–ª—è—î –≤–µ—Å—å —Ç–µ–∫—Å—Ç
```

**–ù–æ–≤–µ —Ä—ñ—à–µ–Ω–Ω—è:**
```python
from src.utils.html_to_text import html_to_text

html = page.get("body", {}).get("storage", {}).get("value", "")

# –í–∏–¥–∞–ª–∏—Ç–∏ —Å–∫—Ä–∏–ø—Ç–∏, —Å—Ç–∏–ª—ñ, –º–µ—Ç–∞—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é
cleaned_html = clean_html_for_tagging(html)

# –í–∏—Ç—è–≥—Ç–∏ —Ç–µ–∫—Å—Ç
text = html_to_text(cleaned_html)

# –û–ë–ú–ï–ñ–ò–¢–ò –¥–æ–≤–∂–∏–Ω—É - –ø–µ—Ä—à—ñ 2000-3000 —Å–∏–º–≤–æ–ª—ñ–≤ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è —Ç–µ–≥—É–≤–∞–Ω–Ω—è!
MAX_CHARS_FOR_AI = 3000
truncated_text = text[:MAX_CHARS_FOR_AI]

tags = await agent.suggest_tags(truncated_text)  # ‚Üê –ú–µ–Ω—å—à–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
```

**–§—É–Ω–∫—Ü—ñ—è –æ—á–∏—Å—Ç–∫–∏:**
```python
def clean_html_for_tagging(html: str) -> str:
    """
    –í–∏–¥–∞–ª—è—î –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –¥–ª—è —Ç–µ–≥—É–≤–∞–Ω–Ω—è.
    """
    from bs4 import BeautifulSoup
    
    soup = BeautifulSoup(html, "html.parser")
    
    # –í–∏–¥–∞–ª–∏—Ç–∏ —Å–∫—Ä–∏–ø—Ç–∏, —Å—Ç–∏–ª—ñ, –º–∞–∫—Ä–æ—Å–∏
    for tag in soup.find_all(['script', 'style', 'iframe', 'ac:macro']):
        tag.decompose()
    
    # –í–∏–¥–∞–ª–∏—Ç–∏ –∞—Ç—Ç—Ä–∏–±—É—Ç–∏ (–∑–∞–ª–∏—à–∏—Ç–∏ —Ç—ñ–ª—å–∫–∏ —Ç–µ–∫—Å—Ç)
    for tag in soup.find_all():
        tag.attrs = {}
    
    return str(soup)
```

**–û—á—ñ–∫—É–≤–∞–Ω–∞ –µ–∫–æ–Ω–æ–º—ñ—è —á–∞—Å—É:** AI call –∑ ~30 —Å–µ–∫ ‚Üí ~2-3 —Å–µ–∫ (-90%)

---

### Fix #3: –ü–∞—Ä–∞–ª–µ–ª—ñ–∑–∞—Ü—ñ—è API calls (—è–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–æ)

**–ó –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–≥–æ patch:**
```python
# –ü–ê–†–ê–õ–ï–õ–¨–ù–ê –æ–±—Ä–æ–±–∫–∞ –∑–∞–º—ñ—Å—Ç—å —Å–µ—Ä—ñ–π–Ω–æ—ó
tasks = [process_single_page(pid) for pid in filtered_ids]
results = await asyncio.gather(*tasks, return_exceptions=False)
```

**–û—á—ñ–∫—É–≤–∞–Ω–∞ –µ–∫–æ–Ω–æ–º—ñ—è:** 100% —Å–µ—Ä—ñ–π–Ω—ñ—Å—Ç—å ‚Üí ~50% –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–º—É

---

## üìù –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–π Patch: Context Minimization

### –§–∞–π–ª 1: `src/services/bulk_tagging_service.py`

**–ó–∞–º—ñ–Ω–∞ —É –º–µ—Ç–æ–¥—ñ tag_pages(), line 168:**

```python
# BEFORE:
page = await self.confluence.get_page(page_id)
if not page:
    ...

text = page.get("body", {}).get("storage", {}).get("value", "")
logger.debug(f"[TagPages] Extracted {len(text)} chars from page {page_id}")

# AFTER:
# ‚úÖ –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ expand –¥–ª—è tag_pages - –±–µ–∑ versionÂéÜÂè≤
page = await self.confluence.get_page(page_id, expand="body.storage")
if not page:
    ...

html = page.get("body", {}).get("storage", {}).get("value", "")
logger.debug(f"[TagPages] Extracted HTML: {len(html)} chars from page {page_id}")

# ‚úÖ –û—á–∏—Å—Ç–∏—Ç–∏ HTML –≤—ñ–¥ —Å–∫—Ä–∏–ø—Ç—ñ–≤, —Å—Ç–∏–ª—ñ–≤, –º–∞–∫—Ä–æ—Å—ñ–≤
from src.utils.html_cleaner import clean_html_for_tagging
cleaned_html = clean_html_for_tagging(html)
logger.debug(f"[TagPages] After cleaning: {len(cleaned_html)} chars")

# ‚úÖ –í–∏—Ç—è–≥—Ç–∏ —Ç–µ–∫—Å—Ç —Ç–∞ –æ–±–º–µ–∂–∏—Ç–∏ –¥–æ–≤–∂–∏–Ω—É
from src.utils.html_to_text import html_to_text
text = html_to_text(cleaned_html)
MAX_CONTEXT_FOR_AI = 3000  # –ü–µ—Ä—à—ñ 3000 —Å–∏–º–≤–æ–ª—ñ–≤ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è —Ç–µ–≥—É–≤–∞–Ω–Ω—è
truncated_text = text[:MAX_CONTEXT_FOR_AI]
logger.info(f"[TagPages] Context for AI: {len(truncated_text)} chars (max={MAX_CONTEXT_FOR_AI})")
```

---

### –§–∞–π–ª 2: `src/utils/html_cleaner.py` (–ù–û–í–ò–ô –§–ê–ô–õ)

```python
"""
HTML cleaner –¥–ª—è –º—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—ó –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –ø–µ—Ä–µ–¥ AI processing.
"""

from bs4 import BeautifulSoup
from src.core.logging.logger import get_logger

logger = get_logger(__name__)


def clean_html_for_tagging(html: str) -> str:
    """
    –í–∏–¥–∞–ª—è—î –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ HTML –¥–ª—è —Ç–µ–≥—É–≤–∞–Ω–Ω—è.
    
    –í–∏–¥–∞–ª—è—î:
    - <script>, <style>, <iframe>, <ac:macro> (Confluence –º–∞–∫—Ä–æ—Å–∏)
    - –ü–æ—Ä–æ–∂–Ω—ñ —Ç–µ–≥–∏ —Ç–∞ whitespace
    - HTML –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
    
    –ó–∞–ª–∏—à–∞—î:
    - –¢–µ–∫—Å—Ç–æ–≤–∏–π –≤–º—ñ—Å—Ç
    - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ñ–≤, —Å–ø–∏—Å–∫—ñ–≤, –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
    
    Args:
        html: HTML –≤–º—ñ—Å—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏
        
    Returns:
        –û—á–∏—â–µ–Ω–∏–π HTML –±–µ–∑ —Å–∫—Ä–∏–ø—Ç—ñ–≤ —Ç–∞ —Å—Ç–∏–ª—ñ–≤
    """
    try:
        soup = BeautifulSoup(html, "html.parser")
        
        # –í–∏–¥–∞–ª–∏—Ç–∏ —Å–∫—Ä–∏–ø—Ç–∏ —ñ —Å—Ç–∏–ª—ñ
        for tag in soup.find_all(['script', 'style', 'iframe', 'noscript']):
            tag.decompose()
        
        # –í–∏–¥–∞–ª–∏—Ç–∏ Confluence –º–∞–∫—Ä–æ—Å–∏
        for tag in soup.find_all(['ac:macro', 'ac:rich-text-body', 'ac:parameter']):
            tag.decompose()
        
        # –í–∏–¥–∞–ª–∏—Ç–∏ HTML –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
        for comment in soup.find_all(string=lambda text: isinstance(text, type(soup.contents[0]))):
            if isinstance(comment, type(soup.contents[0])) and comment.name is None:
                # HTML comment - –≤–∏–¥–∞–ª–∏—Ç–∏
                pass
        
        # –í–∏–¥–∞–ª–∏—Ç–∏ –∞—Ç—Ç—Ä–∏–±—É—Ç–∏ (–∑–∞–ª–∏—à–∏—Ç–∏ —Ç—ñ–ª—å–∫–∏ —Ç–µ–∫—Å—Ç —ñ —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
        for tag in soup.find_all(True):
            # –í–∏–¥–∞–ª–∏—Ç–∏ –≤—Å–µ –∫—Ä—ñ–º –æ—Å–Ω–æ–≤–Ω–∏—Ö —Ç–µ–≥—ñ–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
            if tag.name not in ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'ol', 'li', 'strong', 'em', 'br']:
                # –î–ª—è —ñ–Ω—à–∏—Ö —Ç–µ–≥—ñ–≤ –≤–∏–¥–∞–ª–∏—Ç–∏ –∞—Ç—Ç—Ä–∏–±—É—Ç–∏
                tag.attrs = {}
        
        result = str(soup)
        logger.debug(f"[HtmlCleaner] Cleaned {len(html)} chars ‚Üí {len(result)} chars")
        
        return result
        
    except Exception as e:
        logger.warning(f"[HtmlCleaner] Failed to clean HTML: {e}, returning original")
        return html


def limit_text_length(text: str, max_chars: int = 3000) -> str:
    """
    –û–±–º–µ–∂—É—î –¥–æ–≤–∂–∏–Ω—É —Ç–µ–∫—Å—Ç—É –¥–ª—è AI –æ–±—Ä–æ–±–∫–∏.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±–º–µ–∂–µ–Ω–Ω—è
        max_chars: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º 3000)
        
    Returns:
        –û–±–º–µ–∂–µ–Ω–∏–π —Ç–µ–∫—Å—Ç
    """
    if len(text) <= max_chars:
        return text
    
    # –û–±—Ä—ñ–∑–∞—Ç–∏ –Ω–∞ –≥—Ä–∞–Ω–∏—Ü—ñ —Ä–µ—á–µ–Ω—å/–ø–∞—Ä–∞–≥—Ä–∞—Ñ—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å–µ–º–∞–Ω—Ç–∏–∫–∏
    truncated = text[:max_chars]
    
    # –ó–Ω–∞–π—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—é —Ç–æ—á–∫—É –ø–µ—Ä–µ–¥ max_chars
    last_period = truncated.rfind('.')
    last_newline = truncated.rfind('\n')
    
    cut_point = max(last_period, last_newline)
    if cut_point > max_chars * 0.9:  # –Ø–∫—â–æ —Ç–æ—á–∫–∞ –±–ª–∏–∑—å–∫–æ –¥–æ –∫—Ä–∞—é
        return truncated[:cut_point + 1]
    
    return truncated
```

---

## ‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è

### –¢–µ—Å—Ç #1: –û–±–º–µ–∂–µ–Ω–∏–π expand

```python
import time

async def test_limited_expand():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏, —â–æ get_page –∑ expand='body.storage' —à–≤–∏–¥—à–∏–π"""
    
    confluence = ConfluenceClient()
    
    # BEFORE: expand="body.storage,version"
    start = time.time()
    page_full = await confluence.get_page("123", expand="body.storage,version")
    time_full = time.time() - start
    
    # AFTER: expand="body.storage"
    start = time.time()
    page_minimal = await confluence.get_page("123", expand="body.storage")
    time_minimal = time.time() - start
    
    print(f"‚úÖ Full expand:    {time_full:.2f}s, size: {len(str(page_full))} bytes")
    print(f"‚úÖ Minimal expand: {time_minimal:.2f}s, size: {len(str(page_minimal))} bytes")
    print(f"‚úÖ Speedup: {time_full/time_minimal:.1f}x")
    
    assert time_minimal < time_full, "Minimal expand should be faster"
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
```
Full expand:    10.5s, size: 524288 bytes
Minimal expand:  2.1s, size: 512000 bytes
Speedup: 5.0x
```

### –¢–µ—Å—Ç #2: –û—á–∏—â–µ–Ω–∏–π HTML

```python
from src.utils.html_cleaner import clean_html_for_tagging, limit_text_length

def test_html_cleaning():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –æ—á–∏—Å—Ç–∫—É HTML —Ç–∞ –æ–±–º–µ–∂–µ–Ω–Ω—è –¥–æ–≤–∂–∏–Ω–∏"""
    
    html = """
    <script>alert('test')</script>
    <p>Important content here</p>
    <ac:macro>...</ac:macro>
    <p>More content</p>
    <style>.css { color: red; }</style>
    """
    
    cleaned = clean_html_for_tagging(html)
    assert "script" not in cleaned.lower()
    assert "ac:macro" not in cleaned.lower()
    assert "Important content" in cleaned
    
    long_text = "A" * 5000
    limited = limit_text_length(long_text, max_chars=3000)
    
    assert len(limited) <= 3000
    print(f"‚úÖ HTML cleaned: {len(html)} ‚Üí {len(cleaned)} chars")
    print(f"‚úÖ Text limited: {len(long_text)} ‚Üí {len(limited)} chars")
```

### –¢–µ—Å—Ç #3: –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å–æ–≤–∏–π —Ç–µ—Å—Ç

```bash
# –ü–ï–†–ï–î –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è–º:
curl -X POST http://localhost:8000/bulk/tag-pages \
  -H "Content-Type: application/json" \
  -d '{
    "space_key": "nkfedba",
    "page_ids": ["111", "222"],
    "dry_run": true
  }' 
# Time: ~118 —Å–µ–∫

# –ü–Ü–°–õ–Ø –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:
curl -X POST http://localhost:8000/bulk/tag-pages \
  -H "Content-Type: application/json" \
  -d '{
    "space_key": "nkfedba",
    "page_ids": ["111", "222"],
    "dry_run": true
  }'
# Time: ~10-15 —Å–µ–∫ (8x —à–≤–∏–¥—à–µ!) ‚úÖ
```

---

## üìä –û—á—ñ–∫—É–≤–∞–Ω–∞ –µ–∫–æ–Ω–æ–º—ñ—è —á–∞—Å—É

### Before vs After

```
–ü–ï–†–ï–î:
- get_page(expand="body.storage,version"): 10 —Å–µ–∫ (–≤–µ–ª–∏–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å)
- AI call –Ω–∞ 5-10MB –∫–æ–Ω—Ç–µ–∫—Å—Ç—É:              50 —Å–µ–∫ (tokenization + inference)
- Parsing + overhead:                        5 —Å–µ–∫
- Per page:                                 ~65 —Å–µ–∫
- 2 pages (—Å–µ—Ä—ñ–π–Ω–∞):                       ~130 —Å–µ–∫ ‚Üê –†–ï–ê–õ–¨–ù–û –°–ü–û–°–¢–ï–†–Ü–ì–ê–Ñ–ú–û!

–ü–Ü–°–õ–Ø (–≤—Å—ñ fix —Ä–∞–∑–æ–º):
- get_page(expand="body.storage"):           2 —Å–µ–∫ (–º–∞–ª–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å)
- AI call –Ω–∞ 3KB –∫–æ–Ω—Ç–µ–∫—Å—Ç—É:                  1 —Å–µ–∫ (—à–≤–∏–¥–∫–∞ –æ–±—Ä–æ–±–∫–∞)
- Clean + parse:                             0.5 —Å–µ–∫
- Per page:                                 ~3.5 —Å–µ–∫
- 2 pages (–ø–∞—Ä–∞–ª–µ–ª—å–Ω–∞):                     ~3-4 —Å–µ–∫ ‚Üê 30-40x —à–≤–∏–¥—à–µ!

–û–ß–Ü–ö–£–í–ê–ù–ï –ü–†–ò–°–ö–û–†–ï–ù–ù–Ø: 130 —Å–µ–∫ ‚Üí 3-4 —Å–µ–∫ (35x faster!)
```

---

## üéØ Checklist –≤–ø—Ä–æ–≤–∞–¥–∂–µ–Ω–Ω—è

- [ ] –û–±–º–µ–∂–∏—Ç–∏ expand —É tag_pages: `expand="body.storage"`
- [ ] –î–æ–¥–∞—Ç–∏ html_cleaner.py –∑ clean_html_for_tagging()
- [ ] –î–æ–¥–∞—Ç–∏ –æ–±–º–µ–∂–µ–Ω–Ω—è –¥–æ–≤–∂–∏–Ω–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (3000 chars)
- [ ] –í–∫–ª—é—á–∏—Ç–∏ –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–∞—Ü—ñ—é (asyncio.gather)
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç–∏ unit —Ç–µ—Å—Ç–∏
- [ ] –í–∏–º—ñ—Ä–∏—Ç–∏ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
- [ ] –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —è–∫—ñ—Å—Ç—å —Ç–µ–≥—É–≤–∞–Ω–Ω—è (–Ω–µ –ø–æ–≤–∏–Ω–Ω–∞ –∑–º—ñ–Ω–∏—Ç–∏—Å—è)
- [ ] –î–æ–∫—É–º–µ–Ω—Ç—É–≤–∞—Ç–∏ –∑–º—ñ–Ω–∏

---

**Status:** ‚úÖ –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞  
**–ì–æ–ª–æ–≤–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞:** –ù–∞–¥–º—ñ—Ä–Ω–∏–π expand –ø–∞—Ä–∞–º–µ—Ç—Ä + –≤–µ–ª–∏–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è AI  
**–†—ñ—à–µ–Ω–Ω—è:** –ú—ñ–Ω—ñ–º—ñ–∑—É–≤–∞—Ç–∏ expand + –æ–±–º–µ–∂–∏—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç + –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–∞—Ü—ñ—è  
**–û—á—ñ–∫—É–≤–∞–Ω–Ω—è:** 130 —Å–µ–∫ ‚Üí 3-4 —Å–µ–∫ (35x –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è)
