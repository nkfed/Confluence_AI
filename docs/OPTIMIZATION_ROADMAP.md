# ‚öôÔ∏è –î–û–†–û–ñ–ù–ê –ö–ê–†–¢–ê –û–ü–¢–ò–ú–Ü–ó–ê–¶–Ü–á AI PROVIDERS

## üéØ –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç 1: –ö–†–ò–¢–ò–ß–ù–û (–ø—Ä–æ—Ç—è–≥–æ–º 1-2 –¥–Ω—ñ–≤)

### 1.1 –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ Gemini API Quotas

**–°—Ç–∞—Ç—É—Å:** ‚ùå –ù–ï–í–Ü–î–û–ú–û  
**–í–ø–ª–∏–≤:** –ö–†–ò–¢–ò–ß–ù–ò–ô ‚Äî API –ø–æ–≤–Ω—ñ—Å—Ç—é –±–ª–æ–∫—É—î—Ç—å—Å—è –ø—Ä–∏ –≤–∏—á–µ—Ä–ø–∞–Ω–Ω—ñ –∫–≤–æ—Ç–∏

**–î—ñ—ó:**
```bash
# –ö—Ä–æ–∫ 1: –í—ñ–¥–∫—Ä–∏—Ç–∏ Google Cloud Console
https://console.cloud.google.com/

# –ö—Ä–æ–∫ 2: –ü–µ—Ä–µ–π—Ç–∏ –≤ APIs & Services ‚Üí Quotas
# –®—É–∫–∞—Ç–∏: "Generative Language API"

# –ö—Ä–æ–∫ 3: –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ø–æ—Ç–æ—á–Ω—ñ –∫–≤–æ—Ç–∏
- Requests per minute per user (RPM)
- Tokens per minute per project (TPM)
- Concurrent requests

# –ö—Ä–æ–∫ 4: –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ Usage
- –ó–≤—ñ—Ç –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 24 –≥–æ–¥–∏–Ω–∏
- –ô–º–æ–≤—ñ—Ä–Ω–∞ –ø—Ä–∏—á–∏–Ω–∞: Free tier –º–∞—î –æ–±–º–µ–∂–µ–Ω—ñ –∫–≤–æ—Ç–∏

# –ö—Ä–æ–∫ 5: –Ø–∫—â–æ –∫–≤–æ—Ç–∞ –æ–±–º–µ–∂–µ–Ω–∞
  Option A: Upgrade –Ω–∞ Paid tier ($300+ –∑–∞ –º—ñ—Å—è—Ü—å)
  Option B: –†–æ–∑–ø–æ–¥—ñ–ª–∏—Ç–∏ –∑–∞–ø–∏—Ç–∏ –≤ —á–∞—Å—ñ (queuing)
  Option C: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞ –º–æ–¥–µ–ª—å (Claude, Mistral)
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** Gemini —Å—Ç–∞–Ω–µ —Å—Ç–∞–±—ñ–ª—å–Ω–∏–º, –±–µ–∑ 429 –ø–æ–º–∏–ª–æ–∫

---

### 1.2 –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ Exponential Backoff

**–§–∞–π–ª –¥–ª—è —Ä–µ–¥–∞–∫—Ü—ñ—ó:** `src/core/ai/gemini_client.py`

**–ü–æ—Ç–æ—á–Ω–∏–π –∫–æ–¥ (~line 140-200):**
```python
async def generate(self, prompt: str, **kwargs) -> AIResponse:
    for attempt in range(max_retries):  # max_retries = 2
        try:
            response = self.client.models.generate_content(prompt)
            return parse_response(response)
        except HTTPStatusError as e:
            if e.status_code == 429:
                if attempt < max_retries - 1:
                    await asyncio.sleep(1)  # ‚Üê –ª—ñ–Ω—ñ–π–Ω–∞ –∑–∞—Ç—Ä–∏–º–∫–∞!
                else:
                    raise RuntimeError(f"Rate limit after {max_retries} attempts")
```

**–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∞ –∑–º—ñ–Ω–∞:**
```python
async def generate(self, prompt: str, **kwargs) -> AIResponse:
    max_retries = 4  # –ó–±—ñ–ª—å—à–∏—Ç–∏ –∑ 2
    base_wait = 2  # –°—Ç–∞—Ä—Ç–æ–≤–∞ –∑–∞—Ç—Ä–∏–º–∫–∞
    
    for attempt in range(max_retries):
        try:
            response = self.client.models.generate_content(prompt)
            return parse_response(response)
        except HTTPStatusError as e:
            if e.status_code == 429:
                if attempt < max_retries - 1:
                    # Exponential backoff: 2s ‚Üí 4s ‚Üí 8s ‚Üí 16s
                    wait_time = min(base_wait * (2 ** attempt), 16)
                    logger.warning(f"Rate limit, waiting {wait_time}s before retry {attempt+1}/{max_retries}")
                    await asyncio.sleep(wait_time)
                else:
                    raise RuntimeError(f"Rate limit after {max_retries} attempts")
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** –ë—ñ–ª—å—à–µ —à–∞–Ω—Å—ñ–≤ –Ω–∞ —É—Å–ø—ñ—Ö –ø—Ä–∏ —Ç–∏–º—á–∞—Å–æ–≤–∏—Ö –ª—ñ–º—ñ—Ç–∞—Ö

---

## üéØ –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç 2: –í–ê–ñ–õ–ò–í–û (–ø—Ä–æ—Ç—è–≥–æ–º —Ç–∏–∂–Ω—è)

### 2.1 –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ Client-side Rate Limiting

**–§–∞–π–ª –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è:** `src/core/ai/rate_limiter.py`

```python
import asyncio
from collections import deque
from datetime import datetime
from typing import Callable

class RateLimiter:
    def __init__(self, max_requests_per_minute: int = 60, provider: str = "gemini"):
        self.max_requests = max_requests_per_minute
        self.provider = provider
        self.request_times = deque()
        self.lock = asyncio.Lock()
    
    async def wait_if_needed(self):
        """–ó–∞—Ç—Ä–∏–º–∞–π—Ç–µ –∑–∞–ø–∏—Ç, —è–∫—â–æ –Ω–∞–±–ª–∏–∂–∞—î–º–æ—Å—è –¥–æ –ª—ñ–º—ñ—Ç—É"""
        async with self.lock:
            now = datetime.now()
            
            # –í–∏–¥–∞–ª–∏—Ç–∏ –∑–∞–ø–∏—Ç–∏ —Å—Ç–∞—Ä—à—ñ –∑–∞ 60 —Å–µ–∫—É–Ω–¥
            while self.request_times and (now - self.request_times[0]).total_seconds() > 60:
                self.request_times.popleft()
            
            # –Ø–∫—â–æ –¥–æ—Å—è–≥–ª–∏ –ª—ñ–º—ñ—Ç—É, —á–µ–∫–∞—î–º–æ
            if len(self.request_times) >= self.max_requests:
                wait_time = 60 - (now - self.request_times[0]).total_seconds()
                logger.warning(
                    f"[{self.provider}] Rate limit approaching. "
                    f"Waiting {wait_time:.1f}s before next request"
                )
                await asyncio.sleep(max(0.1, wait_time))
            
            self.request_times.append(datetime.now())
    
    def get_current_rate(self) -> float:
        """–ü–æ–≤–µ—Ä–Ω—É—Ç–∏ –ø–æ—Ç–æ—á–Ω—É —á–∞—Å—Ç–æ—Ç—É –∑–∞–ø–∏—Ç—ñ–≤ –Ω–∞ —Ö–≤–∏–ª–∏–Ω—É"""
        now = datetime.now()
        # –í–∏–¥–∞–ª–∏—Ç–∏ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Ç–∏
        while self.request_times and (now - self.request_times[0]).total_seconds() > 60:
            self.request_times.popleft()
        return len(self.request_times)

# –ì–ª–æ–±–∞–ª—å–Ω—ñ rate limiters
GEMINI_LIMITER = RateLimiter(max_requests_per_minute=40, provider="gemini")  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ
OPENAI_LIMITER = RateLimiter(max_requests_per_minute=60, provider="openai")
```

**–Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ GeminiClient:**
```python
class GeminiClient:
    def __init__(self, api_key: str, model: str = "gemini-2.0-flash-exp"):
        self.api_key = api_key
        self.model = model
        self.rate_limiter = GEMINI_LIMITER
    
    async def generate(self, prompt: str, **kwargs) -> AIResponse:
        # –ß–µ–∫–∞—Ç–∏, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
        await self.rate_limiter.wait_if_needed()
        
        # –†–µ—à—Ç–∞ –ª–æ–≥—ñ–∫–∏...
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** –ó–∞–ø–∏—Ç–∏ —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω—ñ —Ä—ñ–≤–Ω–æ–º—ñ—Ä–Ω–æ, –º–µ–Ω—à–µ 429 –ø–æ–º–∏–ª–æ–∫

---

### 2.2 –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è Prompt –¥–ª—è Gemini

**–ü–æ—Ç–æ—á–Ω–∞ —Å–∏—Ç—É–∞—Ü—ñ—è:**
- Prompt –¥–ª—è tagging: **4465 tokens** (–¥—É–∂–µ –≤–µ–ª–∏–∫–æ)
- Gemini –º–∞—î –æ–±–º–µ–∂–µ–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É –≤—ñ–∫–Ω–æ –∑–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—é

**–î—ñ—ó:**

1. **–°–∫–æ—Ä–æ—Ç–∏—Ç–∏ system prompt:**
```python
# –ü–æ—Ç–æ—á–Ω–∞ –≤–µ—Ä—Å—ñ—è (–¥—É–∂–µ –¥–µ—Ç–∞–ª—ñ–∑–æ–≤–∞–Ω–∞):
TAGGING_PROMPT = """
–¢–∏ ‚Äî –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ–π–Ω–∏–π –∞–≥–µ–Ω—Ç –¥–ª—è Confluence.
–¢–≤–æ—î –∑–∞–≤–¥–∞–Ω–Ω—è ‚Äî –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç...
[20+ —Ä—è–¥–∫—ñ–≤ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π]
–ü—Ä–∞–≤–∏–ª–∞: [–¥–µ—Ç–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫]
...
"""

# –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –≤–µ—Ä—Å—ñ—è:
TAGGING_PROMPT_OPTIMIZED = """
Classify Confluence page text using provided tags only.
Return JSON: {"doc": [], "domain": [], "kb": [], "tool": []}
Max 3 tags per category. Use only if explicitly mentioned.
"""
# ‚Üê 5 —Ä—è–¥–∫—ñ–≤ –≤–º–µ—Å—Ç–æ 20+, –µ–∫–æ–Ω–æ–º—ñ—è ~300 tokens
```

2. **–°–∫–æ—Ä–æ—Ç–∏—Ç–∏ –ø—Ä–∏–∫–ª–∞–¥–∏:**
```python
# –ó–∞–º—ñ—Å—Ç—å 10+ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤
EXAMPLES = [
    # Top 3 high-quality examples only
]
```

3. **–î–æ–¥–∞—Ç–∏ –º–µ–º–æ—ñ–∑–∞—Ü—ñ—é –¥–ª—è instruction tokens:**
```python
# Gemini –ø—ñ–¥—Ç—Ä–∏–º—É—î request caching
# –Ø–∫—â–æ system prompt –æ–¥–Ω–∞–∫–æ–≤–∏–π, –≤—ñ–Ω –∫–µ—à—É—î—Ç—å—Å—è

cached_prompt = """@cached
You are a tagging agent...
"""  # ‚Üê Gemini –∑–∞–ø–∞–º'—è—Ç–∞—î —Ü—ñ —Ç–æ–∫–µ–Ω–∏, –Ω–µ –±—É–¥–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ —Ä–∞—Ö—É–≤–∞—Ç–∏
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** –°–∫–æ—Ä–æ—á–µ–Ω–Ω—è prompt –∑ 4465 –Ω–∞ ~2000-2500 tokens = –±—ñ–ª—å—à–µ —Å–≤–æ–±–æ–¥–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç—É

---

### 2.3 –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Gemini –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤

**–§–∞–π–ª –¥–ª—è —Ä–µ–¥–∞–∫—Ü—ñ—ó:** `.env`

```env
# –ñ–ú–ê–†–ö–ò–ô –ü–ê–†–ê–ú–ï–¢–†–ò –î–õ–Ø TAGGING

# –í–∂–µ –¥–æ–±—Ä–µ:
GEMINI_MODEL=gemini-2.0-flash-exp  # ‚úÖ —à–≤–∏–¥–∫–∞, –¥–µ—à–µ–≤–∞

# –ü–û–¢–†–ï–ë–£–Ñ –ó–ú–Ü–ù–ò:
GEMINI_TEMPERATURE=0.7             # ‚Üí 0.2 (–¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—ó JSON)
GEMINI_MAX_OUTPUT_TOKENS=null      # ‚Üí 200 (–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è JSON)
GEMINI_TOP_P=1.0                   # ‚Üí 0.95 (–º–µ–Ω—å—à–µ –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω–æ—Å—Ç—ñ)
GEMINI_TOP_K=40                    # ‚Üí 20 (–±—ñ–ª—å—à –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∞)

# –ù–û–í–Ü –ü–ê–†–ê–ú–ï–¢–†–ò:
GEMINI_FREQUENCY_PENALTY=0.0       # + 0.1 (—É–Ω–∏–∫–∞—Ç–∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω—å)
GEMINI_PRESENCE_PENALTY=0.0        # + 0.05 (–±—ñ–ª—å—à–µ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω–æ—Å—Ç—ñ)
```

**–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è JSON tagging:**
```env
# –ü—Ä–æ—Ñ—ñ–ª—å: "Stable JSON Output"
GEMINI_TEMPERATURE=0.2
GEMINI_TOP_P=0.95
GEMINI_TOP_K=20
GEMINI_MAX_OUTPUT_TOKENS=200
```

---

## üéØ –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç 3: –¶–Ü–ö–ê–í–û (–∑–∞ 2 —Ç–∏–∂–Ω—ñ)

### 3.1 –ó–∞–ø—Ä–æ–≤–∞–¥–∏—Ç–∏ Batching –¥–ª—è tag-space –æ–ø–µ—Ä–∞—Ü—ñ–π

**–ü–æ—Ç–æ—á–Ω–∞ —Å–∏—Ç—É–∞—Ü—ñ—è:** –ö–æ–∂–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ = –æ–∫—Ä–µ–º–∏–π API –∑–∞–ø–∏—Ç

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è:**
```python
# –ó–∞–º—ñ—Å—Ç—å:
for page in pages:
    tags = await gemini.tag_page(page.body)  # ‚Üê –∫–æ–∂–µ–Ω –∑–∞–ø–∏—Ç –æ–∫—Ä–µ–º–æ

# –ö—Ä–∞—â–µ:
async def batch_tag_pages(pages: List[Page], batch_size: int = 5):
    """–û–±—Ä–æ–±–ª—è–π—Ç–µ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –±–∞—Ç—á–∞–º–∏ –∑ –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–º—É"""
    
    semaphore = asyncio.Semaphore(batch_size)  # –º–∞–∫—Å 5 –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏—Ö
    
    async def tag_with_limit(page):
        async with semaphore:
            await rate_limiter.wait_if_needed()
            return await gemini.tag_page(page.body)
    
    tasks = [tag_with_limit(page) for page in pages]
    return await asyncio.gather(*tasks)
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** + 3x —à–≤–∏–¥—à–µ –¥–ª—è bulk –æ–ø–µ—Ä–∞—Ü—ñ–π (–ø—Ä–∏ –∫–æ–Ω—Ç—Ä–æ–ª—å–æ–≤–∞–Ω—ñ–π –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—Å—Ç—ñ)

---

### 3.2 –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ Monitoring Dashboard

**–§–∞–π–ª –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è:** `src/core/ai/monitoring.py`

```python
from dataclasses import dataclass, field
from typing import Dict, List
from datetime import datetime, timedelta

@dataclass
class ProviderMetrics:
    provider: str
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    rate_limit_errors: int = 0
    total_tokens_used: int = 0
    total_cost_usd: float = 0.0
    avg_latency_ms: float = 0.0
    last_error: str = ""
    last_error_time: datetime = None
    
    @property
    def success_rate(self) -> float:
        if self.total_requests == 0:
            return 0.0
        return (self.successful_requests / self.total_requests) * 100
    
    @property
    def is_healthy(self) -> bool:
        return self.success_rate >= 95.0

# –ú–æ–Ω—ñ—Ç–æ—Ä
class AIProviderMonitor:
    def __init__(self):
        self.metrics: Dict[str, ProviderMetrics] = {}
    
    def record_request(self, provider: str, success: bool, 
                      latency_ms: float, tokens: int, cost: float,
                      error: str = None):
        if provider not in self.metrics:
            self.metrics[provider] = ProviderMetrics(provider=provider)
        
        m = self.metrics[provider]
        m.total_requests += 1
        
        if success:
            m.successful_requests += 1
        else:
            m.failed_requests += 1
            if "429" in (error or ""):
                m.rate_limit_errors += 1
            m.last_error = error
            m.last_error_time = datetime.now()
        
        m.total_tokens_used += tokens
        m.total_cost_usd += cost
        m.avg_latency_ms = (m.avg_latency_ms * (m.total_requests - 1) + latency_ms) / m.total_requests
    
    def get_report(self) -> str:
        report = "üìä AI Provider Health Report\n"
        report += "=" * 60 + "\n"
        
        for provider_name, metrics in self.metrics.items():
            status = "‚úÖ" if metrics.is_healthy else "‚ö†Ô∏è"
            report += f"\n{status} {provider_name.upper()}\n"
            report += f"  Success Rate: {metrics.success_rate:.1f}%\n"
            report += f"  Requests: {metrics.successful_requests}/{metrics.total_requests}\n"
            report += f"  Avg Latency: {metrics.avg_latency_ms:.0f}ms\n"
            report += f"  Tokens: {metrics.total_tokens_used:,}\n"
            report += f"  Cost: ${metrics.total_cost_usd:.3f}\n"
            
            if metrics.rate_limit_errors > 0:
                report += f"  ‚ö†Ô∏è Rate Limits: {metrics.rate_limit_errors}\n"
        
        return report

MONITOR = AIProviderMonitor()
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
```python
# –õ–æ–≥—É–≤–∞—Ç–∏ –∫–æ–∂–µ–Ω –∑–∞–ø–∏—Ç
MONITOR.record_request(
    provider="gemini",
    success=True,
    latency_ms=1532,
    tokens=5163,
    cost=0.0015
)

# –í–∏–≤–µ—Å—Ç–∏ –∑–≤—ñ—Ç
print(MONITOR.get_report())
```

---

## üìã –ß–ï–ö–õ–ò–°–¢ –†–ï–ê–õ–Ü–ó–ê–¶–Ü–á

### –ù–µ–≥–∞–π–Ω–æ (1-2 –¥–Ω—ñ)
- [ ] –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ Gemini API quotas —É Google Cloud Console
- [ ] Upgrade –Ω–∞ Paid tier (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
- [ ] –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ exponential backoff —É `gemini_client.py`

### –¶–µ–π —Ç–∏–∂–¥–µ–Ω—å
- [ ] –°—Ç–≤–æ—Ä–∏—Ç–∏ `rate_limiter.py`
- [ ] –Ü–Ω—Ç–µ–≥—Ä—É–≤–∞—Ç–∏ rate limiter –≤ GeminiClient
- [ ] –û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ prompt (—Å–∫–æ—Ä–æ—Ç–∏—Ç–∏ –∑ 4465 –Ω–∞ 2000-2500 tokens)
- [ ] –û–Ω–æ–≤–∏—Ç–∏ `.env` –∑ –Ω–æ–≤–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ Gemini
- [ ] –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑ –Ω–æ–≤–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

### –ù–∞—Å—Ç—É–ø–Ω–∏–π —Ç–∏–∂–¥–µ–Ω—å
- [ ] –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ batch tagging –¥–ª—è tag-space –æ–ø–µ—Ä–∞—Ü—ñ–π
- [ ] –î–æ–¥–∞—Ç–∏ monitoring dashboard
- [ ] Performance —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑ –Ω–æ–≤–æ—é –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é
- [ ] –î–æ–∫—É–º–µ–Ω—Ç—É–≤–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏

---

## üéØ –û–ß–Ü–ö–£–í–ê–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò

| –ú–µ—Ç—Ä–∏–∫–∞ | –ü–æ—Ç–æ—á–Ω–∞ | –û—á—ñ–∫—É–≤–∞–Ω–∞ | –í–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω–Ω—è |
|---------|---------|-----------|---------------|
| **Gemini Success Rate** | 40% | 95%+ | +140% |
| **Avg Latency (Gemini)** | 1.5s | 1.0s | -33% |
| **Cost per operation** | $0.012 (fallback) | $0.0003 | -97% |
| **Stability** | –ù–µ—Å—Ç–∞–±—ñ–ª—å–Ω–∞ | –°—Ç–∞–±—ñ–ª—å–Ω–∞ | –ö—Ä–∏—Ç–∏—á–Ω–∞ ‚úÖ |
| **Throughput (pages/min)** | ~30 | ~60+ | +100% |

---

**–í–µ—Ä—Å—ñ—è –¥–æ–∫—É–º–µ–Ω—Ç—É:** 1.0  
**–î–∞—Ç–∞:** 2026-01-03  
**–°—Ç–∞—Ç—É—Å:** Ready for implementation
