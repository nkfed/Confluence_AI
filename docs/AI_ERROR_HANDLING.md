# AI Error Handling Documentation

## ğŸ“‹ ĞĞ³Ğ»ÑĞ´

**Error Handling Layer** â€” Ñ†Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ¸ Ğ¿Ğ¾Ğ¼Ğ¸Ğ»Ğ¾Ğº Ğ´Ğ»Ñ AI Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ–Ğ² Ğ· Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¼ fallback Ğ¼ĞµÑ…Ğ°Ğ½Ñ–Ğ·Ğ¼Ğ¾Ğ¼.

**ĞšĞ»ÑÑ‡Ğ¾Ğ²Ñ– Ğ¼Ğ¾Ğ¶Ğ»Ğ¸Ğ²Ğ¾ÑÑ‚Ñ–:**
- âœ… ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ– Ğ²Ğ¸Ğ½ÑÑ‚ĞºĞ¸ Ğ´Ğ»Ñ Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ñ–Ñ—Ğ²
- âœ… ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ fallback Ğ¿Ñ€Ğ¸ Ğ·Ğ±Ğ¾ÑÑ…
- âœ… Ğ§Ñ–Ñ‚ĞºĞ° Ñ–Ñ”Ñ€Ğ°Ñ€Ñ…Ñ–Ñ Ğ¿Ğ¾Ğ¼Ğ¸Ğ»Ğ¾Ğº
- âœ… Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ° Ñ–Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ñ–Ñ Ğ¿Ñ€Ğ¾ Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ¸
- âœ… ĞŸĞµÑ€ĞµĞ´Ğ±Ğ°Ñ‡ÑƒĞ²Ğ°Ğ½Ğ° Ğ¿Ğ¾Ğ²ĞµĞ´Ñ–Ğ½ĞºĞ°
- âœ… Ğ›ĞµĞ³ĞºĞ° Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ° Ğ² Ğ±Ñ–Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ñ–Ñ†Ñ–

## ğŸ¯ ĞĞ°Ğ²Ñ–Ñ‰Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±ĞµĞ½ Error Handling?

### ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: ĞĞµĞ¿ĞµÑ€ĞµĞ´Ğ±Ğ°Ñ‡ÑƒĞ²Ğ°Ğ½Ñ– Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ¸

```python
# Ğ‘ĞµĞ· ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ… Ğ¿Ğ¾Ğ¼Ğ¸Ğ»Ğ¾Ğº
try:
    result = await router.generate("prompt")
except Exception as e:
    # Ğ©Ğ¾ Ñ†Ğµ Ğ·Ğ° Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ°?
    # Ğ§Ğ¸ Ğ²Ğ°Ñ€Ñ‚Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚Ğ¸ retry?
    # Ğ§Ğ¸ fallback ÑĞ¿Ñ€Ğ°Ñ†ÑĞ²Ğ°Ğ²?
    # ğŸ¤· ĞĞµĞ²Ñ–Ğ´Ğ¾Ğ¼Ğ¾!
    logger.error(f"Error: {e}")
```

### Ğ Ñ–ÑˆĞµĞ½Ğ½Ñ: Typed Exceptions

```python
from src.core.ai.errors import (
    ProviderUnavailableError,
    FallbackFailedError,
)

try:
    result = await router.generate("prompt")
    
except ProviderUnavailableError as e:
    # âœ… Ğ—Ñ€Ğ¾Ğ·ÑƒĞ¼Ñ–Ğ»Ğ¾: Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ğ¹
    # ĞœĞ¾Ğ¶Ğ½Ğ° ÑĞ¿Ñ€Ğ¾Ğ±ÑƒĞ²Ğ°Ñ‚Ğ¸ Ñ–Ğ½ÑˆĞ¾Ğ³Ğ¾
    logger.error(f"Provider unavailable: {e}")
    
except FallbackFailedError as e:
    # âœ… Ğ—Ñ€Ğ¾Ğ·ÑƒĞ¼Ñ–Ğ»Ğ¾: Ğ¾Ğ±Ğ¸Ğ´Ğ²Ğ° Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¸ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸Ğ»Ğ¸ÑÑ
    # ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ° Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ°, Ñ‚Ñ€ĞµĞ±Ğ° Ğ°Ğ»ĞµÑ€Ñ‚Ğ¸Ñ‚Ğ¸
    logger.critical(f"All providers failed: {e}")
    send_alert(e)
```

## ğŸ”¥ Ğ’Ğ¸Ğ½ÑÑ‚ĞºĞ¸

### 1. AIProviderError (Base)

**Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ¸Ğ¹ Ğ²Ğ¸Ğ½ÑÑ‚Ğ¾Ğº** Ğ´Ğ»Ñ Ğ²ÑÑ–Ñ… AI provider Ğ¿Ğ¾Ğ¼Ğ¸Ğ»Ğ¾Ğº.

```python
class AIProviderError(Exception):
    """Base exception for all AI provider-related errors"""
    pass
```

**Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ğ½Ñ:**
```python
# Catch all AI provider errors
try:
    result = await router.generate("prompt")
except AIProviderError as e:
    logger.error(f"AI provider error: {e}")
    # Handle any AI error
```

### 2. RateLimitError

**ĞŸĞµÑ€ĞµĞ²Ğ¸Ñ‰ĞµĞ½Ğ¾ Ğ»Ñ–Ğ¼Ñ–Ñ‚ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñ–Ğ²** Ğ´Ğ¾ API.

```python
class RateLimitError(AIProviderError):
    """Exception raised when API rate limit is exceeded"""
    pass
```

**ĞšĞ¾Ğ»Ğ¸ Ğ²Ğ¸Ğ½Ğ¸ĞºĞ°Ñ”:**
- Ğ—Ğ°Ğ±Ğ°Ğ³Ğ°Ñ‚Ğ¾ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñ–Ğ² Ğ·Ğ° ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ñ‡Ğ°Ñ
- Rate limiter Ğ½Ğµ Ğ±ÑƒĞ² Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ğ¸Ğ¹
- ĞĞµÑĞ¿Ğ¾Ğ´Ñ–Ğ²Ğ°Ğ½Ğ¸Ğ¹ ÑĞ¿Ğ»ĞµÑĞº Ñ‚Ñ€Ğ°Ñ„Ñ–ĞºÑƒ

**Ğ¯Ğº Ğ¾Ğ±Ñ€Ğ¾Ğ±Ğ»ÑÑ‚Ğ¸:**
```python
from src.core.ai.errors import RateLimitError
import asyncio

try:
    result = await client.generate("prompt")
except RateLimitError:
    logger.warning("Rate limit exceeded, waiting...")
    await asyncio.sleep(60)  # Wait 1 minute
    result = await client.generate("prompt")  # Retry
```

### 3. ProviderUnavailableError

**ĞŸÑ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ğ¹** Ğ°Ğ±Ğ¾ Ğ½Ğµ ÑĞºĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹.

```python
class ProviderUnavailableError(AIProviderError):
    """Exception raised when AI provider is unavailable or not configured"""
    pass
```

**ĞšĞ¾Ğ»Ğ¸ Ğ²Ğ¸Ğ½Ğ¸ĞºĞ°Ñ”:**
- Provider Ğ½Ğµ Ğ·Ğ°Ñ€ĞµÑ”ÑÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² router
- API key Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–Ğ¹ Ğ°Ğ±Ğ¾ Ğ½ĞµĞ²Ğ°Ğ»Ñ–Ğ´Ğ½Ğ¸Ğ¹
- Provider service Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ğ¹ (downtime)
- ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸ Ğ· Ğ¼ĞµÑ€ĞµĞ¶ĞµÑ
- Primary Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸Ğ²ÑÑ Ñ– Ğ½ĞµĞ¼Ğ°Ñ” fallback

**Ğ¯Ğº Ğ¾Ğ±Ñ€Ğ¾Ğ±Ğ»ÑÑ‚Ğ¸:**
```python
from src.core.ai.errors import ProviderUnavailableError

try:
    result = await router.generate("prompt", provider="openai")
except ProviderUnavailableError as e:
    logger.error(f"OpenAI unavailable: {e}")
    # Try alternative provider
    result = await router.generate("prompt", provider="gemini")
```

### 4. FallbackFailedError

**ĞĞ±Ğ¸Ğ´Ğ²Ğ° Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¸ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸Ğ»Ğ¸ÑÑ** (primary Ñ– fallback).

```python
class FallbackFailedError(AIProviderError):
    """Exception raised when both primary and fallback providers fail"""
    pass
```

**ĞšĞ¾Ğ»Ğ¸ Ğ²Ğ¸Ğ½Ğ¸ĞºĞ°Ñ”:**
- Primary Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸Ğ²ÑÑ
- Fallback Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ Ñ‚Ğ°ĞºĞ¾Ğ¶ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸Ğ²ÑÑ
- ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ° ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ñ–Ñ

**Ğ¯Ğº Ğ¾Ğ±Ñ€Ğ¾Ğ±Ğ»ÑÑ‚Ğ¸:**
```python
from src.core.ai.errors import FallbackFailedError

try:
    result = await router.generate("prompt")
except FallbackFailedError as e:
    logger.critical(f"All providers failed: {e}")
    # Send alert to operations team
    send_alert("Critical: All AI providers failed", str(e))
    # Return error to user
    return {"error": "AI service temporarily unavailable"}
```

## ğŸ”„ Fallback Ğ›Ğ¾Ğ³Ñ–ĞºĞ°

### Ğ¯Ğº Ğ¿Ñ€Ğ°Ñ†ÑÑ” fallback

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User calls router.generate("prompt")        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Try PRIMARY provider (e.g., OpenAI)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                 â”‚
         SUCCESS           FAILURE
            â”‚                 â”‚
            â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Return   â”‚   â”‚ 3. Check if fallback exists  â”‚
    â”‚  Result   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚            â”‚
                          YES           NO
                            â”‚            â”‚
                            â–¼            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ 4. Try FALLBACK  â”‚  â”‚ Raise                   â”‚
              â”‚    (e.g., Gemini)â”‚  â”‚ ProviderUnavailableErrorâ”‚
              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚        â”‚
                SUCCESS  FAILURE
                   â”‚        â”‚
                   â–¼        â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Return   â”‚  â”‚ Raise           â”‚
           â”‚  Result   â”‚  â”‚ FallbackFailed  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ Error           â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ñ–Ñ—

#### Scenario 1: Primary â†’ OK âœ…

```python
router = AIProviderRouter(
    default_provider="openai",
    fallback_provider="gemini"
)

# OpenAI Ğ¿Ñ€Ğ°Ñ†ÑÑ”
result = await router.generate("Hello")
# âœ… Success with OpenAI
# Fallback Ğ½Ğµ Ğ²Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ”Ñ‚ÑŒÑÑ
```

**Ğ›Ğ¾Ğ³:**
```
INFO Generating with provider: openai
INFO Successfully generated with openai
```

#### Scenario 2: Primary â†’ Error â†’ Fallback â†’ OK âœ…

```python
router = AIProviderRouter(
    default_provider="openai",
    fallback_provider="gemini"
)

# OpenAI Ğ¿Ğ°Ğ´Ğ°Ñ”, Gemini Ğ¿Ñ€Ğ°Ñ†ÑÑ”
result = await router.generate("Hello")
# âœ… Success with Gemini (fallback)
```

**Ğ›Ğ¾Ğ³:**
```
INFO Generating with provider: openai
WARNING Provider openai failed: Rate limit exceeded
INFO Attempting fallback to: gemini
INFO Successfully generated with fallback gemini
```

#### Scenario 3: Primary â†’ Error â†’ Fallback â†’ Error âŒ

```python
router = AIProviderRouter(
    default_provider="openai",
    fallback_provider="gemini"
)

# ĞĞ±Ğ¸Ğ´Ğ²Ğ° Ğ¿Ğ°Ğ´Ğ°ÑÑ‚ÑŒ
try:
    result = await router.generate("Hello")
except FallbackFailedError as e:
    # âŒ Both failed
    logger.critical(f"Critical error: {e}")
```

**Ğ›Ğ¾Ğ³:**
```
INFO Generating with provider: openai
WARNING Provider openai failed: Rate limit exceeded
INFO Attempting fallback to: gemini
ERROR Fallback provider gemini also failed: Service unavailable
```

#### Scenario 4: Primary â†’ Error â†’ No Fallback âŒ

```python
router = AIProviderRouter(
    default_provider="openai",
    fallback_provider=None  # No fallback
)

# OpenAI Ğ¿Ğ°Ğ´Ğ°Ñ”, fallback Ğ½ĞµĞ¼Ğ°Ñ”
try:
    result = await router.generate("Hello")
except ProviderUnavailableError as e:
    # âŒ Primary failed, no fallback
    logger.error(f"Provider unavailable: {e}")
```

**Ğ›Ğ¾Ğ³:**
```
INFO Generating with provider: openai
WARNING Provider openai failed: Rate limit exceeded
```

#### Scenario 5: Fallback Same as Primary âŒ

```python
router = AIProviderRouter(
    default_provider="openai",
    fallback_provider="openai"  # Same!
)

# OpenAI Ğ¿Ğ°Ğ´Ğ°Ñ”, fallback Ñ‚Ğ¾Ğ¹ ÑĞ°Ğ¼Ğ¸Ğ¹
try:
    result = await router.generate("Hello")
except ProviderUnavailableError as e:
    # âŒ Primary failed, fallback not attempted
    logger.error(f"Provider unavailable: {e}")
```

**Ğ›Ğ¾Ğ³Ñ–ĞºĞ°:** Ğ¯ĞºÑ‰Ğ¾ fallback Ñ‚Ğ¾Ğ¹ ÑĞ°Ğ¼Ğ¸Ğ¹ Ñ‰Ğ¾ Ñ– primary, Ğ½ĞµĞ¼Ğ°Ñ” ÑĞµĞ½ÑÑƒ Ğ¹Ğ¾Ğ³Ğ¾ Ğ²Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ‚Ğ¸.

## ğŸ¯ Best Practices

### 1. ĞĞµ Ğ»Ğ¾Ğ²Ğ¸Ñ‚Ğ¸ AIProviderError Ğ² Ğ±Ñ–Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ñ–Ñ†Ñ–

```python
# âŒ Bad: Catching too broadly
async def generate_summary(page_id):
    try:
        result = await router.generate(prompt)
        return result.text
    except Exception:
        # Too generic, hides real issues
        return "Error"

# âœ… Good: Let errors propagate
async def generate_summary(page_id):
    # Let AIProviderError propagate
    result = await router.generate(prompt)
    return result.text

# Handle at higher level
try:
    summary = await generate_summary(page_id)
except FallbackFailedError:
    # Send alert
    send_alert("AI service down")
except ProviderUnavailableError:
    # Try alternative approach
    summary = get_cached_summary(page_id)
```

### 2. Ğ›Ğ¾Ğ³ÑƒĞ²Ğ°Ñ‚Ğ¸ Ñ‡ĞµÑ€ĞµĞ· unified logging

```python
from src.core.ai.logging_utils import log_ai_call

# âœ… Good: Unified logging captures errors
result = await log_ai_call(
    provider_name="openai",
    model="gpt-4o-mini",
    operation="summary",
    coro=lambda: provider.generate(prompt)
)
# Errors are automatically logged with context
```

### 3. Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ²Ğ°Ñ‚Ğ¸ health check Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ¼

```python
from src.core.ai.router import AIProviderRouter

router = AIProviderRouter()

# âœ… Good: Check health first
report = await router.explain()

if not report['all_providers_ok']:
    logger.warning("Some providers unhealthy!")
    # Decide whether to proceed

# Start processing
result = await router.generate(prompt)
```

### 4. Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ²Ğ°Ñ‚Ğ¸ rate limit guard

```python
from src.core.ai.rate_limit import SimpleRateLimiter

# âœ… Good: Use rate limiter
limiter = SimpleRateLimiter(calls_per_minute=60)

async def safe_generate(prompt):
    await limiter.acquire()
    return await router.generate(prompt)

# Prevents RateLimitError
```

### 5. Handle ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ– Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ¸

```python
from src.core.ai.errors import FallbackFailedError

try:
    result = await router.generate(prompt)
    
except FallbackFailedError as e:
    # âœ… Good: Critical error handling
    logger.critical(f"All providers failed: {e}")
    
    # Send alert
    send_alert("Critical: AI service down", str(e))
    
    # Notify user
    return {
        "error": "AI service temporarily unavailable",
        "status": "degraded"
    }
```

### 6. Retry Ğ· exponential backoff

```python
import asyncio
from src.core.ai.errors import ProviderUnavailableError

async def generate_with_retry(prompt, max_retries=3):
    for attempt in range(max_retries):
        try:
            return await router.generate(prompt)
            
        except ProviderUnavailableError as e:
            if attempt == max_retries - 1:
                raise  # Last attempt failed
            
            # Exponential backoff
            wait_time = 2 ** attempt  # 1s, 2s, 4s
            logger.warning(f"Retry {attempt + 1}/{max_retries} after {wait_time}s")
            await asyncio.sleep(wait_time)
```

## ğŸ“Š Error Handling Examples

### Example 1: Agent with Error Handling

```python
from src.agents.summary_agent import SummaryAgent
from src.core.ai.router import AIProviderRouter
from src.core.ai.errors import FallbackFailedError, ProviderUnavailableError

async def generate_summary_safe(page_id: str):
    """Generate summary with comprehensive error handling"""
    
    router = AIProviderRouter(
        default_provider="openai",
        fallback_provider="gemini"
    )
    
    agent = SummaryAgent(ai_router=router, ai_provider="openai")
    
    try:
        # Try to generate
        summary = await agent.generate_summary(page_id)
        return {
            "status": "success",
            "summary": summary
        }
        
    except FallbackFailedError as e:
        # Critical: both providers failed
        logger.critical(f"All AI providers failed: {e}")
        send_alert("Critical: AI service down")
        
        return {
            "status": "error",
            "error": "AI service temporarily unavailable",
            "message": "Please try again later"
        }
        
    except ProviderUnavailableError as e:
        # Provider issue, maybe try cache
        logger.error(f"Provider unavailable: {e}")
        
        # Try cached summary
        cached = get_cached_summary(page_id)
        if cached:
            return {
                "status": "success",
                "summary": cached,
                "cached": True
            }
        
        return {
            "status": "error",
            "error": "AI provider unavailable",
            "message": "Please try again later"
        }
```

### Example 2: API Endpoint with Error Handling

```python
from fastapi import FastAPI, HTTPException
from src.core.ai.router import AIProviderRouter
from src.core.ai.errors import FallbackFailedError, ProviderUnavailableError

app = FastAPI()
router = AIProviderRouter()

@app.post("/api/generate")
async def generate_endpoint(prompt: str):
    """Generate text with error handling"""
    
    try:
        result = await router.generate(prompt)
        
        return {
            "status": "success",
            "text": result.text,
            "provider": result.provider,
            "tokens": result.total_tokens
        }
        
    except FallbackFailedError as e:
        # 503 Service Unavailable
        logger.critical(f"All providers failed: {e}")
        raise HTTPException(
            status_code=503,
            detail="AI service temporarily unavailable"
        )
        
    except ProviderUnavailableError as e:
        # 502 Bad Gateway
        logger.error(f"Provider unavailable: {e}")
        raise HTTPException(
            status_code=502,
            detail="AI provider unavailable"
        )
```

### Example 3: Batch Processing with Error Handling

```python
from src.core.ai.router import AIProviderRouter
from src.core.ai.errors import FallbackFailedError

async def batch_generate(prompts: list[str]):
    """Process batch with error handling"""
    
    router = AIProviderRouter()
    results = []
    errors = []
    
    for i, prompt in enumerate(prompts):
        try:
            result = await router.generate(prompt)
            results.append({
                "index": i,
                "status": "success",
                "text": result.text
            })
            
        except FallbackFailedError as e:
            # Log but continue processing
            logger.error(f"Item {i} failed: {e}")
            errors.append({
                "index": i,
                "error": str(e)
            })
        
        except Exception as e:
            # Unexpected error
            logger.error(f"Unexpected error for item {i}: {e}")
            errors.append({
                "index": i,
                "error": f"Unexpected: {e}"
            })
    
    return {
        "total": len(prompts),
        "successful": len(results),
        "failed": len(errors),
        "results": results,
        "errors": errors
    }
```

## ğŸ§ª Testing

### Unit Tests

```bash
pytest tests/core/ai/test_errors_in_router.py -v
```

**12 Ñ‚ĞµÑÑ‚Ñ–Ğ²:**
- âœ… ProviderUnavailableError (3 tests)
  - Unknown provider
  - Primary fails, no fallback
  - Fallback same as primary
- âœ… Fallback success (2 tests)
  - Primary fails, fallback succeeds
  - Explicit provider with fallback
- âœ… FallbackFailedError (2 tests)
  - Both providers fail
  - Error details preserved
- âœ… Successful generation (1 test)
  - Primary succeeds, no fallback needed
- âœ… Error inheritance (2 tests)
  - All inherit from base
  - Can catch with base exception
- âœ… Error messages (2 tests)
  - Provider name in message
  - Both providers in fallback error

### Integration Test

```python
@pytest.mark.asyncio
async def test_full_error_flow():
    """Test complete error handling flow"""
    
    from src.core.ai.router import AIProviderRouter
    from src.core.ai.errors import FallbackFailedError
    
    router = AIProviderRouter()
    
    try:
        result = await router.generate("Test prompt")
        assert result.text  # Should have text
        
    except FallbackFailedError:
        # Both providers failed
        pytest.fail("Both providers failed in integration test")
```

## âœ… ĞŸĞµÑ€ĞµĞ²Ğ°Ğ³Ğ¸ Error Handling Layer

1. âœ… **Type Safety** â€” typed exceptions Ğ´Ğ»Ñ ĞºÑ€Ğ°Ñ‰Ğ¾Ñ— Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ¸
2. âœ… **Clarity** â€” Ğ·Ñ€Ğ¾Ğ·ÑƒĞ¼Ñ–Ğ»Ğ¾ Ñ‰Ğ¾ Ğ¿Ñ–ÑˆĞ»Ğ¾ Ğ½Ğµ Ñ‚Ğ°Ğº
3. âœ… **Predictability** â€” Ğ¿ĞµÑ€ĞµĞ´Ğ±Ğ°Ñ‡ÑƒĞ²Ğ°Ğ½Ğ° Ğ¿Ğ¾Ğ²ĞµĞ´Ñ–Ğ½ĞºĞ°
4. âœ… **Fallback** â€” Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğµ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ½Ñ Ğ½Ğ° fallback
5. âœ… **Debugging** â€” Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ° Ñ–Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ñ–Ñ Ğ¿Ñ€Ğ¾ Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ¸
6. âœ… **Monitoring** â€” Ğ»ĞµĞ³ĞºĞ¾ Ğ»Ğ¾Ğ³ÑƒĞ²Ğ°Ñ‚Ğ¸ Ñ‚Ğ° Ğ¼Ğ¾Ğ½Ñ–Ñ‚Ğ¾Ñ€Ğ¸Ñ‚Ğ¸
7. âœ… **Graceful** â€” graceful degradation Ğ¿Ñ€Ğ¸ Ğ·Ğ±Ğ¾ÑÑ…
8. âœ… **Production Ready** â€” Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğ´Ğ»Ñ production

## ğŸš€ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğ´Ğ¾ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ğ½Ñ!

Error Handling Layer Ğ·Ğ°Ğ±ĞµĞ·Ğ¿ĞµÑ‡ÑƒÑ” Ğ½Ğ°Ğ´Ñ–Ğ¹Ğ½Ñƒ Ñ‚Ğ° Ğ¿ĞµÑ€ĞµĞ´Ğ±Ğ°Ñ‡ÑƒĞ²Ğ°Ğ½Ñƒ Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºÑƒ Ğ¿Ğ¾Ğ¼Ğ¸Ğ»Ğ¾Ğº Ñƒ Ğ²Ğ°ÑˆÑ–Ğ¹ Multi-AI Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ–!
